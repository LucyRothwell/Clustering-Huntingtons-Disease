{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SuStaIn tutorial using simulated data\n",
    "\n",
    "Written by Alex Young in April 2020. Please email alexandra.young@kcl.ac.uk with any questions.\n",
    "\n",
    "This tutorial demonstrates how to run Subtype and Stage Inference (SuStaIn) using simulated data. SuStaIn is an unsupervised learning algorithm that identifies subgroups of individuals with distinct biomarker progression patterns. See [Young et al. Nature Communications 2018](https://doi.org/10.1038/s41467-018-05892-0) for more details.\n",
    "\n",
    "SuStaIn is a generalisable algorithm in which you can choose how to model the progression of biomarkers within a subtype. In this tutorial I use the linear z-score model I used in [Young et al. 2018](https://doi.org/10.1038/s41467-018-05892-0), but it is possible to use other models of biomarker evolution, such as the event-based model.\n",
    "\n",
    "*Note: I've just learnt python recently so my code might not be as simple as it could be - any suggestions for improvements welcome!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the python packages needed to generate simulated data for the tutorial\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import sklearn.model_selection\n",
    "import pandas as pd\n",
    "import pylab\n",
    "\n",
    "# import the simulation functions from pySuStaIn needed to generate simulated data\n",
    "from simfuncs import generate_random_sustain_model, generate_data_sustain\n",
    "\n",
    "# import the functions for z-score SuStaIn\n",
    "from ZscoreSustain  import ZscoreSustain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The linear z-score model\n",
    "\n",
    "The linear z-score model I use in this tutorial describes a subtype progression pattern as the linear evolution of biomarkers between different z-scores. Figure 1 below shows an example of what this model looks like for a single subtype. The model is indexed by a set of discrete stages. Each stage corresponds to a biomarker reaching a new z-score from the set of z-scores for each biomarker, Z_vals. Each biomarker starts with a minimum value of 0 at stage 0 and reaches a maximum of Z_max at the final stage of the progression. The number of stages is determined by the number of biomarkers and z-scores in Z_vals. The SuStaIn algorithm identifies subgroups of individuals and their progression patterns - for the linear z-score model the progression pattern would be the ordering of the different biomarker z-scores in Z_vals - gt_sequence below.\n",
    "\n",
    "You can play around generating different sequences and altering the settings of the linear z-score model using the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N = 5         # number of biomarkers\n",
    "\n",
    "# SuStaInLabels = []\n",
    "\n",
    "# for i in range(N):\n",
    "#         SuStaInLabels.append('Biomarker '+ str(i)) # labels of biomarkers for plotting\n",
    "        \n",
    "# Z_vals = np.array([[1,2,3]]*N)     # Z-scores for each biomarker\n",
    "# Z_max = np.array([5]*N)           # maximum z-score\n",
    "\n",
    "# # To demonstrate how to set different biomarkers to have different z-scores,\n",
    "# # set biomarker 0 to have z-scores of 1 and 2 only and a maximum of 3\n",
    "# # to do this change the corresponding row of Z_vals to read 1 2 0\n",
    "# # and change the corresponding row of Z_max to 3\n",
    "# Z_vals[np.array(0),np.array(2)] = 0\n",
    "# Z_max[np.array(0)] = 3\n",
    "\n",
    "# # and set biomarker 2 to have a z-score of 1 only and a maximum of 2\n",
    "# # to do this change the corresponding row of Z_vals to read 1 0 0 \n",
    "# # and change the corresponding row of Z_max to 2 \n",
    "# Z_vals[np.array(2),np.array([1,2])] = 0\n",
    "# Z_max[np.array(2)] = 2\n",
    "\n",
    "\n",
    "# # generate a random sequence for the linear z-score model\n",
    "# gt_sequence = generate_random_sustain_model(Z_vals, 1)\n",
    "\n",
    "# # ignore this part, it's only necessary so that the generate_data_sustain function\n",
    "# # can be used in this demo setting\n",
    "# gt_stages = np.array([0])\n",
    "# gt_subtypes = np.array([0])\n",
    "\n",
    "# # this code generates data from z-score sustain \n",
    "# # - here i've just output the z-score model itself rather than any datapoints\n",
    "# _, _, gt_stage_value = generate_data_sustain(gt_subtypes,\n",
    "#                                              gt_stages,\n",
    "#                                              gt_sequence,\n",
    "#                                              Z_vals,\n",
    "#                                              Z_max)\n",
    "\n",
    "# # ignore this part, just calculates some parameters of sustain to output below\n",
    "stage_zscore            = np.array([y for x in Z_vals.T for y in x])\n",
    "stage_zscore            = stage_zscore.reshape(1,len(stage_zscore))\n",
    "IX_select               = stage_zscore>0\n",
    "stage_zscore            = stage_zscore[IX_select]\n",
    "stage_zscore            = stage_zscore.reshape(1,len(stage_zscore))\n",
    "num_zscores             = Z_vals.shape[1]\n",
    "IX_vals                 = np.array([[x for x in range(N)]] * num_zscores).T\n",
    "stage_biomarker_index   = np.array([y for x in IX_vals.T for y in x])\n",
    "stage_biomarker_index   = stage_biomarker_index.reshape(1,len(stage_biomarker_index))\n",
    "stage_biomarker_index   = stage_biomarker_index[IX_select]\n",
    "stage_biomarker_index   = stage_biomarker_index.reshape(1,len(stage_biomarker_index))\n",
    "\n",
    "# # print out some of the values and plot a picture of the model\n",
    "# print('Simulated sequence:',(gt_sequence.astype(int).flatten()))\n",
    "# print('At the beginning of the progression (stage 0) the biomarkers have scores of 0')\n",
    "# print('At the stages:',1+np.arange(np.array(stage_zscore).shape[1]))\n",
    "# print('the biomarkers:',stage_biomarker_index[:,gt_sequence.astype(int).flatten()].flatten())\n",
    "# print('reach z-scores of:',stage_zscore[:,gt_sequence.astype(int).flatten()].flatten())\n",
    "# print('At the end of the progression (stage',np.array(stage_zscore).shape[1]+2,') the biomarkers reach scores of:',Z_max)\n",
    "# print('The z-score model assumes individuals belong to some unknown stage of this progression,')\n",
    "# print('with gaussian noise with a standard deviation of 1 for each biomarker')\n",
    "\n",
    "# temp_stages = np.array(range(np.array(stage_zscore).shape[1]+2))\n",
    "# for b in range(N):\n",
    "#     ax = plt.plot(temp_stages, gt_stage_value[b,:,:])\n",
    "\n",
    "# _ = plt.xlabel('SuStaIn stage')    \n",
    "# _ = plt.ylabel('Z-score')    \n",
    "# _ = plt.legend(SuStaInLabels)\n",
    "# _ = plt.title('Figure 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important note on the linear z-score model\n",
    "\n",
    "It's natural to think of the progression pattern in Figure 1 as linear in time but this isn't necessarily the case. For example, the time between stages 2 and 3 may be much longer than between stages 8 and 9. This means that the shape of the trajectories may look quite different if indexed by time (although the general order in which the biomarkers progress to different z-scores would remain the same). The linear z-score model simply describes the patient snapshots you would expect to see in a cross-sectional dataset for any particular subtype at a particular stage. The subtypes and stages are considered as hidden variables, which the SuStaIn algorithm identifies directly from the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating simulated data\n",
    "\n",
    "This section of code generates simulated data for the tutorial. Any variables labelled as 'gt' (ground truth) are for generating the simulated data only and would typically not be known beforehand in a real dataset.\n",
    "\n",
    "You can ignore many of the settings below for now, but in particular\n",
    "- N_S_gt is the number of subtypes to simulate\n",
    "- gt_f is the proportion of individuals belonging to each subtype\n",
    "- gt_sequence is the order in which each biomarker approaches each z-score for each subtype\n",
    "- gt_subtypes is the subtype of each individual\n",
    "- gt_stages is the stage of each individual along the progression pattern of their subtype\n",
    "\n",
    "You can alter these to get a feel for how SuStaIn works on different simulated datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5         # number of biomarkers\n",
    "\n",
    "M = 868       # number of observations ( e.g. subjects )\n",
    "M_control               = 146       # number of these that are control subjects\n",
    "# N_S_gt                  = 2         # number of ground truth subtypes\n",
    "\n",
    "SuStaInLabels           = []\n",
    "for i in range(N):\n",
    "        SuStaInLabels.append( 'Biomarker '+str(i)) # labels of biomarkers for plotting\n",
    "        \n",
    "Z_vals                  = np.array([[1,2,3]]*N)     # Z-scores for each biomarker\n",
    "Z_max                   = np.array([5]*N)           # maximum z-score\n",
    "   \n",
    "# # ground truth proportion of individuals belonging to each subtype    \n",
    "# gt_f                    = [1+0.5*x for x in range(N_S_gt)]\n",
    "# gt_f                    = [x/sum(gt_f) for x in gt_f][::-1]\n",
    "\n",
    "# # ground truth sequence for each subtype\n",
    "# gt_sequence             = generate_random_sustain_model(Z_vals,\n",
    "#                                                         N_S_gt)\n",
    "\n",
    "# simulate subtypes and stages for individuals, including a control population at stage 0\n",
    "# N_k                     = np.sum(Z_vals>0)+1\n",
    "# gt_subtypes             = np.random.choice(range(N_S_gt), M, replace=True, p=gt_f)\n",
    "# gt_stages_control       = np.zeros((M_control,1))\n",
    "# gt_stages               = np.concatenate((gt_stages_control,\n",
    "#                                          np.ceil(np.random.rand(M-M_control,1)*N_k)),\n",
    "#                                         axis=0)\n",
    "\n",
    "# # generate simulated data\n",
    "# data, gt_data_denoised, gt_stage_value = generate_data_sustain(gt_subtypes,\n",
    "#                                                                gt_stages,\n",
    "#                                                                gt_sequence,\n",
    "#                                                                Z_vals,\n",
    "#                                                                Z_max)\n",
    "\n",
    "# # ignore this part, just calculates some parameters of sustain to output below\n",
    "# stage_zscore            = np.array([y for x in Z_vals.T for y in x])\n",
    "# stage_zscore            = stage_zscore.reshape(1,len(stage_zscore))\n",
    "# IX_select               = stage_zscore>0\n",
    "# stage_zscore            = stage_zscore[IX_select]\n",
    "# stage_zscore            = stage_zscore.reshape(1,len(stage_zscore))\n",
    "# num_zscores             = Z_vals.shape[1]\n",
    "# IX_vals                 = np.array([[x for x in range(N)]] * num_zscores).T\n",
    "# stage_biomarker_index   = np.array([y for x in IX_vals.T for y in x])\n",
    "# stage_biomarker_index   = stage_biomarker_index.reshape(1,len(stage_biomarker_index))\n",
    "# stage_biomarker_index   = stage_biomarker_index[IX_select]\n",
    "# stage_biomarker_index   = stage_biomarker_index.reshape(1,len(stage_biomarker_index))\n",
    "\n",
    "# for s in range (N_S_gt):\n",
    "#     # print out the parameters\n",
    "#     print('For subtype',s,'(',gt_f[s]*100,'% of individuals)')\n",
    "#     print('Simulated sequence:',(gt_sequence[s,:].astype(int).flatten()))\n",
    "#     print('At the beginning of the progression (stage 0) the biomarkers have scores of 0')\n",
    "#     print('At the stages:',1+np.arange(np.array(stage_zscore).shape[1]))\n",
    "#     print('the biomarkers:',stage_biomarker_index[:,gt_sequence[s,:].astype(int).flatten()].flatten())\n",
    "#     print('reach z-scores of:',stage_zscore[:,gt_sequence[s,:].astype(int).flatten()].flatten())\n",
    "#     print('At the end of the progression (stage',np.array(stage_zscore).shape[1]+2,') the biomarkers reach scores of:',Z_max)\n",
    "#     print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The SuStaIn algorithm\n",
    "\n",
    "SuStaIn identifies subtypes with distinct progression patterns from cross-sectional data. The algorithm proceeds hierarchically, first fitting a single subtype to the data, then two, then three, etc., up to a maximum number of subtypes chosen by the user. The fitting of the nth subtype model works but splitting each of the previous n-1 clusters into two and then using this as an initialisation to fit the n subtype model. For each of the n subtype models, SuStaIn uses MCMC sampling to estimate the uncertainty in the subtype progression patterns and the proportion of individuals that belong to each subtype. The optimal number of subtypes is selected by using cross-validation to compute the cross-validation information criterion (CVIC)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data for SuStaIn\n",
    "\n",
    "The data for SuStaIn needs to be z-scored relative to a control population such that the mean of the control population is 0 and the standard deviation of the control population is 1. To do this simply subtract the mean of the control population from your data and divide by the standard deviation of the control population. Double check that if you apply this transformation to the control population only that the control population has a mean of 0 and a standard deviation of 1. The data further needs to be transformed to increase in z-score with disease progression. If the biomarkers you are using decrease with disease progression you need to multiply the data for those biomarkers by -1.\n",
    "\n",
    "I'd suggest the following workflow for getting your data ready to run SuStaIn on.\n",
    "\n",
    "1. Regress out the effects of covariates. Learn the effects of covariates in a control population and use this model to regress out the effect of covariates for all the subjects. Learning the model in the control population will avoid regressing out disease effects, which you want to keep in your dataset.\n",
    "\n",
    "2. Calculate the mean and standard deviation of each biomarker in your control dataset, mean_control and std_control.\n",
    "\n",
    "3. Z-score your data by taking (data-mean_control)/std_control.\n",
    "\n",
    "4. Identify any biomarkers that decrease with disease progression, these will have mean_data < mean_control. Multiply the data for these biomarkers by -1.\n",
    "\n",
    "Steps 2-4 are illustrated in the section below but will have little effect on the simulated data because it is generated as z-scores already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucyrothwell/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3057: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# LUCY* ADDED\n",
    "enroll = pd.read_csv(\"/Users/lucyrothwell/Google_Drive/MSc_Comp/9_Dissertation/Data - Enroll HD/enroll.csv\", delimiter=',')\n",
    "# Only baseline visits\n",
    "enroll_baseline = enroll[enroll['visit'].values == [\"Baseline\"]]\n",
    "# Controls vs gen_pos\n",
    "enroll_controls = enroll_baseline[enroll_baseline['hdcat'].values == [4]]\n",
    "enroll_gen_pos = enroll_baseline[enroll_baseline['hdcat'].values != [4]]\n",
    "# DATA TO USE: Clinical features x 5, gen_pos - missing dropped\n",
    "data = enroll_gen_pos[[\"miscore\", \"tfcscore\", \"mmsetotal\", \"irascore\", \"exfscore\"]].dropna()\n",
    "# extract data for control subjects\n",
    "data_control = enroll_controls[[\"miscore\", \"tfcscore\", \"mmsetotal\", \"irascore\", \"exfscore\"]].dropna()\n",
    "\n",
    "# compute the mean and standard deviation of the control population\n",
    "mean_control = np.mean(data_control,axis=0)\n",
    "std_control = np.std(data_control,axis=0)\n",
    "\n",
    "# z-score the data\n",
    "data = (data-mean_control)/std_control\n",
    "# data_control = (data_control-mean_control)/std_control\n",
    "\n",
    "# # multiply data for decreasing biomarkers by -1\n",
    "# IS_decreasing = np.mean(data,axis=0)<np.mean(data_control,axis=0)\n",
    "# data[np.tile(IS_decreasing,(M,1))] = -1*data[np.tile(IS_decreasing,(M,1))]\n",
    "# data_control[np.tile(IS_decreasing,(M_control,1))] = -1*data_control[np.tile(IS_decreasing,(M_control,1))]\n",
    "\n",
    "# # Check that the mean of the control population is 0\n",
    "# # print('Mean of controls is ',np.mean(data_control,axis=0))\n",
    "# # Check that the standard deviation of the control population is 1\n",
    "# print('Standard deviation of controls is ',np.std(data_control,axis=0))\n",
    "# # Check that the mean of the whole dataset is positive\n",
    "# print('Mean of whole dataset is ',np.mean(data,axis=0))\n",
    "# # Check that the standard deviation of the whole dataset is greater than 1\n",
    "# print('Standard deviation of whole dataset is ',np.std(data,axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing the settings\n",
    "The SuStaIn algorithm requires the following inputs.\n",
    "\n",
    "### data\n",
    "The data you want to run SuStaIn on, of size M subjects by N biomarkers. This needs to be z-scored in the way described in the previous section.\n",
    "\n",
    "### Z_vals\n",
    "This is the set of z-scores you want to include for each biomarker. The more z-scores you use the longer the SuStaIn algorithm will take to run. Z_vals has size N biomarkers by Z z-scores. If you have more z-scores for some biomarkers than others you can simply leave zeros at the end of biomarker rows with fewer z-scores.\n",
    "\n",
    "### Z_max\n",
    "The maximum z-score reached at the end of the progression, with size N biomarkers by 1. I'd suggest choosing a value around the 95th percentile of your data but you can experiment with different values. I typically choose an integer for interpretability but you don't have to.\n",
    "\n",
    "### SuStaInLabels\n",
    "The names of the biomarkers you are using, for plotting purposes.\n",
    "\n",
    "### N_startpoints\n",
    "The number of startpoints to use when fitting the subtypes hierarchichally. I'd suggest using 25.\n",
    "\n",
    "### N_S_max\n",
    "The maximum number of subtypes to fit. I'd suggest starting with a lower number - maybe three - and then increasing that if you're getting a significantly better fit with the maximum number of subtypes. You can judge this roughly from the MCMC plot. To properly evaluate the optimal number of subtypes you need to run cross-validation.\n",
    "\n",
    "### N_iterations_MCMC\n",
    "The number of iterations for the MCMC sampling of the uncertainty in the progression pattern. I'd recommend using 1x10^5 or 1x10^6.\n",
    "\n",
    "### output_folder\n",
    "Choose an output folder for the results.\n",
    "\n",
    "### dataset_name\n",
    "Name the results files outputted by SuStaIn.\n",
    "\n",
    "### use_parellel_startpoints\n",
    "Boolean for whether or not to parallelize the startpoints.\n",
    "\n",
    "### Additional note\n",
    "There are approximate and exact versions of the computation of the data likelihood for the linear z-score model. Currently the python version only supports the approximate version. If you want to use the exact version please see the Matlab version at https://github.com/ucl-pond/SuStaInMatlab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input the settings for z-score SuStaIn\n",
    "# To make the tutorial run faster I've set \n",
    "# N_startpoints = 10 and N_iterations_MCMC = int(1e4)\n",
    "# I recommend using N_startpoints = 25 and \n",
    "# N_iterations_MCMC = int(1e5) or int(1e6) in general though\n",
    "N_startpoints = 10\n",
    "N_S_max = 3\n",
    "N_iterations_MCMC = int(1e4)\n",
    "output_folder = \"/Users/lucyrothwell/Google_Drive/MSc_Comp/9_Dissertation/SuStaIn-master\"\n",
    "dataset_name = \"Enroll_Sustain_Ouput\"\n",
    "sustain_input = ZscoreSustain(data,\n",
    "                              Z_vals,\n",
    "                              Z_max,\n",
    "                              SuStaInLabels,\n",
    "                              N_startpoints,\n",
    "                              N_S_max, \n",
    "                              N_iterations_MCMC, \n",
    "                              output_folder, \n",
    "                              dataset_name, \n",
    "                              False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deleting previous SuStaIn results if necessary\n",
    "\n",
    "This code snippet deletes any previous SuStaIn results. By default the SuStaIn code checks for previous results to avoid running the algorithm again unnecessarily so you'll need to run this section each time you generate a new simulated dataset that you want to fit the SuStaIn model. If you don't want to overwrite your previous results you can choose a new dataset_name and/or output_folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if os.path.exists(output_folder):\n",
    "#     shutil.rmtree(output_folder)\n",
    "# # output_folder = 'sim2'    \n",
    "# # dataset_name = 'sim2' \n",
    "# sustain_input = ZscoreSustain(data,\n",
    "#                               Z_vals,\n",
    "#                               Z_max,\n",
    "#                               SuStaInLabels,\n",
    "#                               N_startpoints,\n",
    "#                               N_S_max, \n",
    "#                               N_iterations_MCMC, \n",
    "#                               output_folder, \n",
    "#                               dataset_name, \n",
    "#                               False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the SuStaIn algorithm\n",
    "\n",
    "We're finally ready to run the SuStaIn algorithm! The main outputs are samples_sequence and samples_f. samples_sequence gives MCMC samples of the ordering of the biomarker z-scores for each n subtype model. samples_f gives MCMC samples of the proportion of individuals that belong to each subtype for each n subtype model. These can be found in the outputted files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to find pickle file: /Users/lucyrothwell/Google_Drive/MSc_Comp/9_Dissertation/SuStaIn-master/Enroll_Sustain_Ouput_subtype0.pickle. Running SuStaIn model for 0 subtype.\n",
      "Finding ML solution to 1 cluster problem\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucyrothwell/Google_Drive/MSc_Comp/9_Dissertation/SuStaIn-master/ZscoreSustain.py:241: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  p_perm_k_norm                       = p_perm_k_weighted / np.tile(np.sum(np.sum(p_perm_k_weighted, 1), 1).reshape(M, 1, 1), (1, N + 1, N_S))  # the second summation axis is different to Matlab version\n",
      "/Users/lucyrothwell/Google_Drive/MSc_Comp/9_Dissertation/SuStaIn-master/ZscoreSustain.py:241: RuntimeWarning: invalid value encountered in true_divide\n",
      "  p_perm_k_norm                       = p_perm_k_weighted / np.tile(np.sum(np.sum(p_perm_k_weighted, 1), 1).reshape(M, 1, 1), (1, N + 1, N_S))  # the second summation axis is different to Matlab version\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-b4ca2d9c83b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# runs the sustain algorithm with the inputs set in sustain_input above\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msustain_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_sustain_algorithm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Google_Drive/MSc_Comp/9_Dissertation/SuStaIn-master/AbstractSustain.py\u001b[0m in \u001b[0;36mrun_sustain_algorithm\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    137\u001b[0m                 \u001b[0mml_sequence_mat_EM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m                 \u001b[0mml_f_mat_EM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m                 \u001b[0mml_likelihood_mat_EM\u001b[0m        \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_estimate_ml_sustain_model_nplus1_clusters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__sustainData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mml_sequence_prev_EM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mml_f_prev_EM\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#self.__estimate_ml_sustain_model_nplus1_clusters(self.__data, ml_sequence_prev_EM, ml_f_prev_EM)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mseq_init\u001b[0m                    \u001b[0;34m=\u001b[0m \u001b[0mml_sequence_EM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Google_Drive/MSc_Comp/9_Dissertation/SuStaIn-master/AbstractSustain.py\u001b[0m in \u001b[0;36m_estimate_ml_sustain_model_nplus1_clusters\u001b[0;34m(self, sustainData, ml_sequence_prev, ml_f_prev)\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mml_sequence_mat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0mml_f_mat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m             \u001b[0mml_likelihood_mat\u001b[0m               \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_find_ml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msustainData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Overall ML likelihood is'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mml_likelihood\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Google_Drive/MSc_Comp/9_Dissertation/SuStaIn-master/AbstractSustain.py\u001b[0m in \u001b[0;36m_find_ml\u001b[0;34m(self, sustainData)\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m~\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_output_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0mpool_output_list\u001b[0m                \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_output_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m         \u001b[0mml_sequence_mat\u001b[0m                     \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msustainData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetNumStages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN_startpoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#np.zeros((1, self.stage_zscore.shape[1], self.N_startpoints))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Google_Drive/MSc_Comp/9_Dissertation/SuStaIn-master/AbstractSustain.py\u001b[0m in \u001b[0;36m_find_ml_iteration\u001b[0;34m(self, sustainData, seed_num)\u001b[0m\n\u001b[1;32m    646\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m         \u001b[0m_\u001b[0m                               \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_perform_em\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msustainData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_init\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mthis_ml_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthis_ml_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthis_ml_likelihood\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Google_Drive/MSc_Comp/9_Dissertation/SuStaIn-master/AbstractSustain.py\u001b[0m in \u001b[0;36m_perform_em\u001b[0;34m(self, sustainData, current_sequence, current_f)\u001b[0m\n\u001b[1;32m    798\u001b[0m             \u001b[0mcandidate_sequence\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m             \u001b[0mcandidate_f\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m             \u001b[0mcandidate_likelihood\u001b[0m            \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimise_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msustainData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_f\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    801\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m             \u001b[0mHAS_converged\u001b[0m                   \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_likelihood\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcurrent_likelihood\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_likelihood\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_likelihood\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1e-6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Google_Drive/MSc_Comp/9_Dissertation/SuStaIn-master/ZscoreSustain.py\u001b[0m in \u001b[0;36m_optimise_parameters\u001b[0;34m(self, sustainData, S_init, f_init)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mmax_likelihood\u001b[0m              \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossible_likelihood\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 \u001b[0mthis_S\u001b[0m                      \u001b[0;34m=\u001b[0m \u001b[0mpossible_sequences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossible_likelihood\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mmax_likelihood\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m                 \u001b[0mthis_S\u001b[0m                      \u001b[0;34m=\u001b[0m \u001b[0mthis_S\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m                 \u001b[0mS_opt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m                    \u001b[0;34m=\u001b[0m \u001b[0mthis_S\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m                 \u001b[0mthis_p_perm_k\u001b[0m               \u001b[0;34m=\u001b[0m \u001b[0mpossible_p_perm_k\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossible_likelihood\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mmax_likelihood\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# runs the sustain algorithm with the inputs set in sustain_input above\n",
    "sustain_input.run_sustain_algorithm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Just added this to demonstrate what happens if you re-run the SuStaIn algorithm \n",
    "# # with the same dataset name and folder as previously\n",
    "# # The code recognises the files are there already rather than re-running SuStaIn\n",
    "# # This is useful if you want to increase the number of subtypes without \n",
    "# # starting right from the beginning again\n",
    "# sustain_input.run_sustain_algorithm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with ground truth\n",
    "\n",
    "Figure 3 shows the expected progression patterns for the simulated data in the form of positional variance diagrams so it's easier to compare the output of SuStaIn with the ground truth from the simulated data. In a positional variance diagram each entry tells you the probability each biomarker has reached each z-score at each SuStaIn stage. Here, z-scores of 1 are shown in red, 2 in magenta and 3 in blue. I've plotted the positional variance diagrams in Figure 3 without any uncertainty. You'd expect the results from the simulated dataset to have a similar progression pattern on average to those in Figure 3, but with uncertainty due to the simulated noise. Figure 4 shows the output of SuStaIn for the ground truth number of subtypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Output a figure showing the ground truth\n",
    "# temp_gt_sequence = gt_sequence.reshape((gt_sequence.shape[0],gt_sequence.shape[1],1))\n",
    "# temp_gt_f = np.asarray(gt_f).reshape(len(gt_f),1)\n",
    "# ZscoreSustain._plot_sustain_model(sustain_input,temp_gt_sequence,temp_gt_f,M)\n",
    "# _ = plt.suptitle('Figure 3: Ground truth progression pattern')\n",
    "\n",
    "# # The code below opens the results for the ground truth number of subtypes\n",
    "# # and plots the output\n",
    "# s = N_S_gt-1\n",
    "# pickle_filename_s           = output_folder + '/' + dataset_name + '_subtype' + str(s) + '.pickle'\n",
    "# pickle_filepath             = Path(pickle_filename_s)\n",
    "# pickle_file                 = open(pickle_filename_s, 'rb')\n",
    "# loaded_variables            = pickle.load(pickle_file)\n",
    "# samples_sequence            = loaded_variables[\"samples_sequence\"]\n",
    "# samples_f                   = loaded_variables[\"samples_f\"]\n",
    "# pickle_file.close()\n",
    "\n",
    "# ZscoreSustain._plot_sustain_model(sustain_input,samples_sequence,samples_f,M)\n",
    "# _ = plt.suptitle('Figure 4: SuStaIn output')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessing the output\n",
    "\n",
    "Now we've run the SuStaIn algorithm, we need to assess the output and decide whether to change any of the settings. \n",
    "\n",
    "### MCMC trace\n",
    "\n",
    "The first thing to look at is the MCMC trace (Figure 5 below). It should be periodic, i.e. with a structure that regularly repeats itself, rather than having long flat sections where it gets stuck at a particular likelihood. If this isn't the case SuStaIn is not working well on your data. There's some troubleshooting you can try:\n",
    "- Check that your data is z-scored correctly\n",
    "- Check that the choice of z-scores (Z_vals and Z_max) are sensible\n",
    "- Check that your data looks normally distributed in your control population\n",
    "-- if not, try an alternative version of SuStaIn that might be more suitable for your data, e.g. SuStaIn using a KDE event-based model for non normally distributed data \n",
    "- Increase the number of startpoints (N_startpoints)\n",
    "- Increase the number of MCMC samples (N_iterations_MCMC)\n",
    "\n",
    "### Histograms of model likelihood\n",
    "The next thing to look at are histograms of the model likelihood (Figure 6 below). Whilst the number of subtypes should be determined through cross-validation, these histograms can give a reasonable indication of the number of subtypes in your dataset, which will enable you to decide whether to fit more subtypes and what to set as the maximum number of subtypes for the cross-validation. When there's a large overlap between the histograms of the model likelihood as you increase the subtypes it means that the likelihood isn't improving very much when you increase the number of subtypes, which means you've probably gone past the optimal number of subtypes. You want to fit enough subtypes so that at least one model is too complex (has too many subtypes) for your data so that you can be sure you've chosen the optimal number of subtypes. If you're not seeing overlapping histograms you need to increase N_S_max and run SuStaIn again from your previous setting of N_S_max.\n",
    "\n",
    "### Positional variance diagrams\n",
    "If the end stages of the positional variance diagrams look very blurry with no clear predominant progression pattern, it usually means that there aren't many individuals that fit well with the end stages of the progression. If this is the case you might want to consider removing some biomarker z-scores and re-running SuStaIn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # go through each subtypes model and plot MCMC samples of the likelihood\n",
    "# for s in range(N_S_max):\n",
    "#     pickle_filename_s           = output_folder + '/' + dataset_name + '_subtype' + str(s) + '.pickle'\n",
    "#     pickle_filepath             = Path(pickle_filename_s)\n",
    "#     pickle_file                 = open(pickle_filename_s, 'rb')\n",
    "#     loaded_variables            = pickle.load(pickle_file)\n",
    "#     samples_likelihood          = loaded_variables[\"samples_likelihood\"]\n",
    "#     pickle_file.close()\n",
    "\n",
    "#     _ = plt.figure(0)\n",
    "#     _ = plt.plot(range(N_iterations_MCMC), samples_likelihood, label=\"subtype\" + str(s))\n",
    "#     _ = plt.figure(1)\n",
    "#     _ = plt.hist(samples_likelihood, label=\"subtype\" + str(s))\n",
    "    \n",
    "# _ = plt.figure(0)\n",
    "# _ = plt.legend(loc='upper right')\n",
    "# _ = plt.xlabel('MCMC samples')\n",
    "# _ = plt.ylabel('Log likelihood')\n",
    "# _ = plt.title('Figure 5: MCMC trace')\n",
    "    \n",
    "# _ = plt.figure(1)\n",
    "# _ = plt.legend(loc='upper right')\n",
    "# _ = plt.xlabel('Log likelihood')  \n",
    "# _ = plt.ylabel('Number of samples')  \n",
    "# _ = plt.title('Figure 6: Histograms of model likelihood')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation\n",
    "\n",
    "To determine the optimal number of subtypes it's necessary to perform cross-validation and compute the cross-validation information criterion (CVIC). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified cross-validation\n",
    "It's a good idea to use stratified training and test sets so you have similar numbers of cases and controls in each fold, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # identify a control population\n",
    "# index_control           = np.reshape(gt_stages,(M))==0\n",
    "\n",
    "# # label cases and controls to perform stratified cross-validation\n",
    "# labels                  = 1 * np.ones(data.shape[0], dtype=int) \n",
    "# labels[index_control]   = 0\n",
    "\n",
    "# # choose the number of folds - here i've used three for speed but i recommend 10 typically\n",
    "# N_folds                  = 3\n",
    "\n",
    "# # generate stratified cross-validation training and test set splits\n",
    "# cv                       = sklearn.model_selection.StratifiedKFold(n_splits=N_folds, \n",
    "#                                                                    shuffle=True)\n",
    "# cv_it                    = cv.split(data, labels)\n",
    "\n",
    "# test_idxs                = []\n",
    "# for train, test in cv_it:\n",
    "#     test_idxs.append(test)\n",
    "# test_idxs                = np.array(test_idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing cross-validation\n",
    "\n",
    "Next you need to run the cross-validation on your training folds and validate on the test folds. The code below does this sequentially for all folds. It's also possible to specify a specific fold if you wanted to run each fold of the cross-validation separately in parallel (e.g. on the cluster)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # perform cross-validation and output the cross-validation information criterion and\n",
    "# # log-likelihood on the test set for each subtypes model and fold combination\n",
    "# CVIC, loglike_matrix     = sustain_input.cross_validate_sustain_model(test_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Just added this to demonstrate what happens if you re-run the cross-validation \n",
    "# # with the same dataset name and folder as previously\n",
    "# # The code recognises the files are there already rather than re-running SuStaIn\n",
    "# # This is useful if you want to increase the number of subtypes without \n",
    "# # starting right from the beginning again\n",
    "\n",
    "# CVIC, loglike_matrix     = sustain_input.cross_validate_sustain_model(test_idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing the optimal number of subtypes\n",
    "\n",
    "The optimal number of subtypes is chosen using the CVIC, shown in Figure 7 below. The CVIC is an information criterion (like the AIC/BIC/WAIC) that balances model complexity with model accuracy, with a lower CVIC indicating a better balance between the two. Generally speaking, the model with the lowest CVIC is the best. However, you do sometimes get a very small improvement (less than ~6) in the CVIC with a more complex model, in which case I would tend to favour the less complex (i.e. fewer subtypes) model.\n",
    "\n",
    "Another useful metric to look at is the log-likelihood of each subtypes model on the test set, shown in Figure 8. A better model should show a consistent improvement in the test set log-likelihood across folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # go through each subtypes model and plot the log-likelihood on the test set and the CVIC\n",
    "# print(\"CVIC for each subtype model: \" + str(CVIC))\n",
    "# print(\"Average test set log-likelihood for each subtype model: \" + str(np.mean(loglike_matrix, 0)))\n",
    "\n",
    "# _ = plt.figure(1)    \n",
    "# _ = plt.plot(np.arange(N_S_max,dtype=int),CVIC)\n",
    "# _ = plt.xticks(np.arange(N_S_max,dtype=int))\n",
    "# _ = plt.ylabel('CVIC')  \n",
    "# _ = plt.xlabel('Subtypes model') \n",
    "# _ = plt.title('Figure 7: CVIC')\n",
    "\n",
    "# _ = plt.figure(0)\n",
    "# df_loglike                                 = pd.DataFrame(data = loglike_matrix, columns = [\"s_\" + str(i) for i in range(sustain_input.N_S_max)])\n",
    "# df_loglike.boxplot(grid=False)\n",
    "# for i in range(sustain_input.N_S_max):\n",
    "#     y                                   = df_loglike[[\"s_\" + str(i)]]\n",
    "#     x                                   = np.random.normal(1+i, 0.04, size=len(y)) # Add some random \"jitter\" to the x-axis\n",
    "#     pylab.plot(x, y, 'r.', alpha=0.2)\n",
    "# _ = plt.ylabel('Log likelihood')  \n",
    "# _ = plt.xlabel('Subtypes model') \n",
    "# _ = plt.title('Figure 8: Test set log-likelihood across folds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validated positional variance diagrams\n",
    "\n",
    "Another useful output of the cross-validation that you can look at are positional variance diagrams averaged across cross-validation folds. These give you an idea of the variability in the progression patterns across different training datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this part estimates cross-validated positional variance diagrams\n",
    "for i in range(N_S_max):\n",
    "    sustain_input.combine_cross_validated_sequences(i+1, N_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Output a figure showing the ground truth\n",
    "# temp_gt_sequence = gt_sequence.reshape((gt_sequence.shape[0],gt_sequence.shape[1],1))\n",
    "# temp_gt_f = np.asarray(gt_f).reshape(len(gt_f),1)\n",
    "# ZscoreSustain._plot_sustain_model(sustain_input,temp_gt_sequence,temp_gt_f,M)\n",
    "# _ = plt.suptitle('Figure 9: Ground truth progression pattern')\n",
    "\n",
    "# # The code below opens the results for the ground truth number of subtypes\n",
    "# # and plots the output\n",
    "# s = N_S_gt-1\n",
    "# pickle_filename_s           = output_folder + '/' + dataset_name + '_subtype' + str(s) + '.pickle'\n",
    "# pickle_filepath             = Path(pickle_filename_s)\n",
    "# pickle_file                 = open(pickle_filename_s, 'rb')\n",
    "# loaded_variables            = pickle.load(pickle_file)\n",
    "# samples_sequence            = loaded_variables[\"samples_sequence\"]\n",
    "# samples_f                   = loaded_variables[\"samples_f\"]\n",
    "# pickle_file.close()\n",
    "\n",
    "# ZscoreSustain._plot_sustain_model(sustain_input,samples_sequence,samples_f,M)\n",
    "# _ = plt.suptitle('Figure 10: SuStaIn output')\n",
    "\n",
    "# sustain_input.combine_cross_validated_sequences(N_S_gt, N_folds)\n",
    "# _ = plt.suptitle('Figure 11: Cross-validated SuStaIn output')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subtyping and staging\n",
    "\n",
    "Once you've used the CVIC to choose the optimal number of subtypes you can use the SuStaIn output from that subtypes model to subtype and stage individuals in your dataset. This will already have been output by the SuStaIn algorithm, you can extract the outputs using the code below. The outputs are\n",
    "\n",
    "### ml_subtype and prob_ml_subtype\n",
    "The maximum likelihood subtype and the probability of that subtype for each individual.\n",
    "\n",
    "### ml_stage and prob_ml_stage\n",
    "The maximum likelihood stage and the probability of that stage for each individual.\n",
    "\n",
    "### prob_subtype, prob_stage and prob_subtype_stage\n",
    "The probability each individual belongs to each subtype, to each stage, and to each subtype and stage combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = N_S_gt-1\n",
    "# pickle_filename_s           = output_folder + '/' + dataset_name + '_subtype' + str(s) + '.pickle'\n",
    "# pickle_filepath             = Path(pickle_filename_s)\n",
    "# pickle_file                 = open(pickle_filename_s, 'rb')\n",
    "# loaded_variables            = pickle.load(pickle_file)\n",
    "# ml_subtype                  = loaded_variables[\"ml_subtype\"]\n",
    "# prob_ml_subtype             = loaded_variables[\"prob_ml_subtype\"]\n",
    "# ml_stage                    = loaded_variables[\"ml_stage\"]\n",
    "# prob_ml_stage               = loaded_variables[\"prob_ml_stage\"]\n",
    "# prob_subtype                = loaded_variables[\"prob_subtype\"]\n",
    "# prob_stage                  = loaded_variables[\"prob_stage\"]\n",
    "# prob_subtype_stage          = loaded_variables[\"prob_subtype_stage\"]\n",
    "# pickle_file.close()              \n",
    "\n",
    "# You can also subtype and stage new data using\n",
    "# N_samples                       = 1000\n",
    "# ml_subtype,                  \\\n",
    "# prob_ml_subtype,             \\\n",
    "# ml_stage,                    \\\n",
    "# prob_ml_stage,               \\\n",
    "# prob_subtype,                \\\n",
    "# prob_stage,                  \\\n",
    "# prob_subtype_stage          = sustain_input.subtype_and_stage_individuals_newData(new_data,\n",
    "#                                                                                   samples_sequence,\n",
    "#                                                                                   samples_f,\n",
    "#                                                                                   N_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subtyping and staging using cross-validated models\n",
    "\n",
    "The code below subtypes and stages individuals using the cross-validated positional variance diagrams in Figure 11."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = N_S_gt-1\n",
    "# Nfolds                              = len(test_idxs)\n",
    "# for fold in range(Nfolds):\n",
    "#     pickle_filename_fold_s  = sustain_input.output_folder + '/' + sustain_input.dataset_name + '_fold' + str(fold) + '_subtype' + str(s) + '.pickle'\n",
    "#     pickle_filepath         = Path(pickle_filename_fold_s)\n",
    "\n",
    "#     pickle_file             = open(pickle_filename_fold_s, 'rb')\n",
    "\n",
    "#     loaded_variables        = pickle.load(pickle_file)\n",
    "\n",
    "#     samples_sequence        = loaded_variables[\"samples_sequence\"]\n",
    "#     samples_f               = loaded_variables[\"samples_f\"]\n",
    "    \n",
    "#     pickle_file.close()\n",
    "    \n",
    "#     if fold == 0:\n",
    "#         samples_sequence_cval    = samples_sequence\n",
    "#         samples_f_cval           = samples_f\n",
    "#     else:\n",
    "#         samples_sequence_cval    = np.concatenate((samples_sequence_cval, samples_sequence), axis=2)\n",
    "#         samples_f_cval           = np.concatenate((samples_f_cval, samples_f), axis=1)\n",
    "                    \n",
    "# N_samples                       = 1000\n",
    "# ml_subtype_cval,             \\\n",
    "# prob_ml_subtype_cval,        \\\n",
    "# ml_stage_cval,               \\\n",
    "# prob_ml_stage_cval,          \\\n",
    "# prob_subtype_cval,           \\\n",
    "# prob_stage_cval,             \\\n",
    "# prob_subtype_stage_cval          = sustain_input.subtype_and_stage_individuals_newData(data,\n",
    "#                                                                                        samples_sequence_cval,\n",
    "#                                                                                        samples_f_cval,\n",
    "#                                                                                        N_samples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
